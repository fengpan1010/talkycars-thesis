After a comprehensive proposal for a cooperative perception system, including a novel modeling approach and an elaborate distributed software architecture, has been presented in the previous chapters, this chapter aims to evaluate the system with respect to different aspects.

\Cref{sec:problem_analysis:goals_requirements} presented a set of goals and requirements to be met by the proposed system. While previous chapters already discussed how most of them are individually addressed, a few demand for further investigation or empirical assessment. Accordingly, a two-fold evaluation is conducted. The first part concerns about evaluating the proposed \textbf{software architecture} in terms of performance, specifically with respect to the requirements of scalability (NF-C2) and efficiency (NF-C3). The second part of the evaluation aims to assess the system's qualitative \textbf{performance in cooperative perception} tasks, motivated by the overall goal of this thesis to facilitate the improvement of connected, autonomous vehicles' average perception quality (cf. \cref{sec:problem_analysis:goals_requirements}). Both parts are split into four section each, that describe the respective evaluation's specific goal and methodology, explain certain implementation details, present the result and eventually discuss them in a brief conclusion.

\section{Performance Evaluation}
\label{sec:evaluation:performance_evaluation}
\Cref{sec:problem_analysis:goals_requirements} stated the non-functional requirements for the system to be able to handle 202 concurrent network participants at minimum and to aim for low latency and on-vehicle load. The following evaluating thoroughly assesses the previously developed system with respect to both criteria, i.e. \textbf{system scalability} and \textbf{communication efficiency}.

\subsection{Methodology}
\label{sec:evaluation:performance_evaluation:methodology}
First, one or more metrics needs to be determined with respect to which the evaluation of the above criteria should be conducted.

Concerning scalability, a precise quantity is given as a requirement, which refers to the minimum number of concurrent clients (i.e. vehicles, pedestrians, etc.) the system is expected to handle. Assuming a fixed per-vehicle message publish rate – which is in accordance with the previously introduced \textit{periodic push} principle – this translates to a \textbf{minimum number of observation messages}, i.e. state representations, the edge node must be able to process at a time. While the concrete message rate is a parameter that can be varied over the course of the evaluation, the hard minimum requirement of 202 concurrent vehicles is given. That is, assuming the entire system to operate at \SI{10}{Hz} (i.e. both client- and server-side publish rate), the fusion node must reliably process 2020 \si{observations\per\second} without dropping below that rate.

Concerning the second criterion, communication efficiency, average \textbf{latency in milliseconds} and average \textbf{message size in kilobytes} per vehicle and per observation are chosen to be used as metrics. In this specific context, latency refers to the average delay of a shared observation to receive an ego vehicle. While \todo{Include timing table} constitutes a detailed explanation of how this latency is composed, it essentially represents the average "'outdatedness"' of a CP message.