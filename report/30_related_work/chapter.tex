This chapter aims to provide the reader with an overview of current research and state-of-the-art in the field of cellular V2X communication and cooperative perception.
\par
\bigskip

In accordance with the multiple goals of this thesis introduced in \cref{ch:introduction} and \cref{ch:problem_analysis}, related work can, in the broadest sense, be separated into three sections. On the one hand, relevant publications about \textbf{environment modeling, traffic scene representation and message exchange formats} for cooperative perception are examined in \cref{sec:related_work:environment_modeling_state_representation}. Secondly, an overview of existing \textbf{CP systems} is presented and different approaches are discussed in \cref{sec:related_work:cooperative_perception}. Finally, related work on \textbf{cellular-based V2X} is presented.

\section{Environment Modeling \& State Representation}
\label{sec:related_work:environment_modeling_state_representation}
An essential requirement for high-level CP is to have a uniform way to first model the current environment state and second represent that model in form of exchangeable data structures. It is worth noting that this is not necessarily required in the case of low- or feature level CP (see \cref{subsec:background:sensor_fusion}), where either raw sensor readings or only basic information is shared.

An appropriate state representation should, at a minimum, include information about position and dynamics of the sender vehicle and all other surrounding traffic participants. For the former, the European Telecommunications Standards Institute (ETSI) has defined a standard for so called \textbf{Cooperative Awareness Messages} (CAM) \cite{EuropeanTelecommunicationsStandardsInstituteETSI2011}, which is used by Rauch et al. \cite{Rauch2011}. It includes, among others, the sender vehicle's type, its dimensions, position, heading, speed and acceleration as well as respective confidences. To share information about surrounding obstacles in addition, the simplest way is to send \textbf{object lists} that include such. For this purpose, Rauch et al. \cite{Rauch2011} defined the \textbf{Cooperative Perception Message} (CPM) in 2011. Since 2017, the ETSI is working on a similar specification with the same name \cite{EuropeanTelecommunicationsStandardsInstituteETSI2019}. It includes an object list of up to 255 traffic participants \cite{Thandavarayan2019} with attributes similar to those included in CAMs. However, none of both specifications is publicly accessible, yet. Therefore, they can not serve as a basis for this thesis.

Despite pure object lists, another way to share the perception of one's local environment is to model it in the form of \textbf{occupancy grids} or \textit{driveable area} maps \cite{pieringermodellierung}. However, to the best of our knowledge, no CP solution exists that relies on exchanging occupancy grids.

Kohlhaas et al. \cite{Kohlhaas2014} first introduced the concept of \textbf{semantic scene representation} (or \textit{semantic state representation}), which is further advanced by Wolf et al. \cite{Wolf2018} to \textit{"'combine low level attributes with high level relational knowledge in a generic way"'}. They explain several advantages of including semantic, relational information among entities over exchanging plain object lists or occupancy grids. In \cite{Petrich2018}, semantic modeling is picked up again and combined with the idea to use \textbf{Probabilistic Entity Relationship} models for state representation under uncertainty. For none of these three approaches did the authors share a complete meta-model or ontology for traffic scenes.

A few further approaches to modeling and state representation in the context of automated driving are mentioned in appendix \cref{subsec:appendix:texts:related_work:state_represtation}.
\par
\bigskip

In summary, the previously mentioned takes on modeling and representation of road scenes constitute great building blocks for a CP system. This work aims to combine some of their conceptions to come up with a holistic way to (1) model a traffic scene by all relevant aspects, (2) represent it in an appropriate format and (3) define in what form to efficiently transfer it over the wire (or wirelessly). 

\section{Cooperative Perception}
\label{sec:related_work:cooperative_perception}
Different approaches to design a cooperative perception system have already been published in the past, each of them placing a different focus.
\par
\bigskip

An early take in the field of V2X communication and – in the broadest sense – also cooperative perception was presented by Olaverri-Monreal et al. \cite{Olaverri-Monreal2010}. Based on VANETs, they propose a \textit{see-through system} that allows a driver to virtually perceive the road in front of a large obstacle, e.g. a truck, blocking her sight. To achieve this, DSRC is used to exchange raw camera images between connected participants. However, this approach is somewhat special in a way that it define only an driver assistance system (or ADAS) rather than a CP-system for driverless cars in the sense of this work.
\par
\bigskip

Secondly, as part of the Ko-PER research project\footnote{\url{http://ko-fas.de/41-0-Ko-PER---Kooperative-Perzeption.html}} the authors of \cite{Rauch2011} propose a system architecture based on \textbf{track-to-track fusion}, in which local- and global fusion is performed in separate steps to solve the problem of correlated data. Communication is based on IEEE 802.11p and utilizes CAMs and self-defined CPMs, for which they distinguish further between iCPMs (infrastructure) and vCPMs (vehicle), depending on the type of sender. Primary objective of their studies is to get detailed insights about \textbf{latency and transmission range} in CP scenarios. Eventually, the system is evaluated in both a laboratory and a real-world setup involving two cars. While their findings are essential for understanding performance-relevant parameters in V2X setups, the evaluation might have been conducted for more realistic scenarios with many traffic participants in addition.

Complementing their previous work in the field of CP, the authors of \cite{Rauch2012} intensively study methods for \textbf{temporal and spatial alignment} of cooperative perception messages. A motion model is used to predict observations to current time on the receiver side. In addition, they compare two types of possible transformations to accurately estimate an object's spatial position as combination of local- and received observations. While \cite{Rauch2011} is concerned with communication aspects, \cite{Rauch2012} mainly addresses fusion. Findings from both works are well qualified to be incorporated into a more comprehensive solution. 
\par
\bigskip

While the above studies focus on techniques and parameters within the process of CP itself, \cite{liu2013motion} investigates the impact of CP on \textbf{motion planning} tasks. It is suggested to use local observations for short-term navigation and combined, global observations for longer-term planning. Therefor, a cost map is continuously re-constructed, that additionally includes weights corresponding to the underlying observations' \textbf{reliability of perception (ROP)}. Instead of IEEE 802.11p, their connected vehicles use conventional WiFi (802.11n) for P2P communication. Their custom state model does not include any additional information except the probability (confidence) for the quadruple state $X \in \{\chi_{correct}, \chi_{opposite}, \chi_{offroad}, \chi_{roadobst}\}$ of a certain location being driveable or not. As a result of evaluating planning quality with respect to trajectory smoothness and accumulated cost they found CP to be beneficial.

Another evidence for the positive effect of CP on path planning is given by the authors' subsequent publication \cite{kim2013cooperative}. This complementary work mainly addresses the problems of \textbf{vehicle identification}, \textbf{delay compensation} and merging \textbf{occupancy grid maps}, which are used as an environment model. In contrast to previously mentioned systems, most of which either use high- or feature level fusion, \cite{kim2013cooperative} is based on low-level fusion, i.e. raw sensor observations (LiDAR and camera) are exchanged. 
\par
\bigskip

The system design proposed by Calvo et al. \cite{Calvo2017} is the most comprehensive one in this collection, as it presents a 3+1 level CP architecture to be used as an \textit{obstacle avoidance framework}. DSRC-based V2V communication with IEEE 802.11p is used to exchange participants' immediate local surrounding. Long-range, \textbf{cellular}, LTE-based V2I communication facilitates the exchange of more global observations to be used for high-level tasks like traffic re-routing. In addition, their concept also includes I2I communication between RSUs. In comparison to previously mentioned approaches, which mostly cover certain CP-related aspect, the present paper focuses on conceptually outlining a \textbf{system architecture}. However, neither an environment model nor a concrete state representation or message format are presented and it is not made clear what kinds of information are exchanged at all. 
\par
\bigskip

\cite{Chen2019} is the most recent publication in the field of CP and relies on low-level fusion of 3D LiDAR point clouds. After motivating their approach and outlining several accompanying challenges, the author present their DSRC-based system design. Since raw sensor data is sent, the design does not include the specification of an environment model. Instead, particular emphasis is laid on (1) the \textbf{fusion of point clouds}, (2)\textbf{ deep-learning-based object detection} and (3) \textbf{optimization of network utilization}, i.a. by determining a certain \textbf{region of interest} (ROI) for every frame. As a consequence of their evaluation, the authors find that the effective sensing area can successfully be expanded with CP to capture previously unknown obstacles. 
\par
\bigskip

One of the most comprehensive and closely related projects is Ko-HAF \cite{Hohm2019}, sponsored by the German Federal Ministry of Education and Research. As a holistic, V2V solution it comprises, among others, message- and format specification and the definition and implementation of an overall system architecture. As a \textit{"'standard for the exchange of information between vehicle sensor and back-end solutions"'} they present SENSORIS as an extension to the Sensor Data Ingestion Interface (SDII) format specification by HERE Maps\footnote{\url{https://developer.here.com/olp/documentation/sdii-data-spec/topics/introduction.html}}. The presented system architecture involves their so called \textit{Safety Server} as a \textbf{central software component} to be responsible for data consolidation, fusion and redistribution. Participant vehicles communicate with it via cellular (LTE) network and exchange binary serialized messages via HTTP and MQTT. However, while structurally and technically very similar, their approach is not meant to be used for CP in the sense of this work. Instead of aspiring high-precision collaborative awareness and understanding of dynamic traffic scenes for driverless cars, they rather attempt to collaboratively \textbf{build and update a global, "'learning"' map} for ADAS. In other words, they aim for collaborative SLAM, to some extent. Accordingly, the system's focus is on exchanging static road information – especially road signs and lane topology and markings – on the one hand and traffic events and incidents (like construction zones, congestions, stopped cars, etc.) with temporal validity on the other. It is not designed for high dynamicity and does not support to exchange information about surrounding traffic participants. 

\section{Cellular V2X Communication}
\label{sec:related_work:cellular_v2x_communication}
With respect to cellular V2X communication – as opposed to DSRC-based solutions – recent standards are being developed by 3GPP most notably with the publication of \cite{3GPP2019}.

In addition, \cite{QualcommTechnologiesInc.2018} conducted comprehensive experiments to measure the performance of LTE and 5G networks with respect to Cooperative Perception and found 5G to be well suited for these use cases. 

This is complemented by the results of \cite{5GAutomotiveAssociation2016}, whose authors found cellular, 5G-based communication to be superior over DSRC / ITS-G5 for CP tasks.

\section{Summary}
\label{sec:related_work:summary}
Great research has already been contributed to the fields of traffic scene modeling, environment state representation for autonomous driving, cooperative perception and (cellular-) vehicle-to-everything communication. However, several limitations exist with current approaches, that are discussed in greater detail in \cref{ch:problem_analysis}. Most notably, the majority of existing CP solutions in literature rely on DSRC-based VANET communication topologies and on-vehicle data fusion, though the rise of high-performance cellular networks allows for entirely new concepts and system design patterns. Accordingly, this work builds up on previous findings and investigates new possibilities enabled through technological advances to design a holistic, modern system. 